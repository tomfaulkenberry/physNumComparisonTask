---
title             : "A shifted Wald decomposition of the numerical size-congruity effect: Support for a late interaction account"
shorttitle        : "Shifted Wald model of size-congruity effect"

author: 
  - name          : "Thomas J. Faulkenberry"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychological Sciences, Box T-0820, Tarleton State University, Stephenville, TX 76401"
    email         : "faulkenberry@tarleton.edu"
  - name          : "Adriana D. Vick"
  - name          : "Kristen A. Bowman"
  

affiliation:
  - institution   : "Tarleton State University"

author_note: >
  This paper was written in R-Markdown with code for data analysis integrated into the text. The data were *born open* [@rouder2016] and are freely available (along with the Markdown script) at https://git.io/vAEE8. The authors would like to thank Ken Sobel and an anonymous reviewer for their helpful comments on an earlier draft of this paper.

abstract: >
  Decisions involving comparisons of Arabic number digits often exhibit an interference between the physical size of the digit and the implied numerical magnitude, a phenomenon called the size-congruity effect.  Related research over the past four decades has yielded two competing models of the phenomenon: an early interaction account, where interference between numerical and physical magnitude occurs at an early encoding stage, and a late interaction account, where the interference occurs downstream as response competition during the decision process.  In the present study, we asked participants to compare the physical sizes of pairs of Arabic digits.  We fit the resulting response time distributions with a shifted Wald model, a single boundary accumulator model, which gave us estimates of information accumulation rate (drift rate), response threshold, and nondecision time.  We found that incongruity between physical size and numerical magnitude affected the decision-related estimates of drift rate and response threshold.  Further, a Bayesian analysis confirmed a null effect of congruity on nondecision time.  These results indicate that the observed interference originates from decision-related processes, lending further support for a late interaction account of the size-congruity effect.
  
keywords          : "Size congruity effect, response time modeling, accumulator model, shifted Wald distribution"
wordcount         : " "

bibliography      : ["references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r start, include = FALSE}
library(papaja)
library(tidyverse)
library(BayesFactor)
library(cowplot)
source("https://raw.githubusercontent.com/tomfaulkenberry/shiftedWald/master/waldFunctions.R")

```

The ability of humans to compare relative magnitudes of environmental stimuli is an important skill that is rooted in basic evolutionary mechanisms [@cantlon2006].  This ability is exhibited regularly in two different types of judgments.  One type of judgment is based on *physical magnitude*, where competing items are judged based on physical size characteristics (e.g., area, volume, etc.).  For example, one might choose the larger of two sandwiches from a plate by deciding which appears to have the larger volume.  Another type of judgment is based on *numerical magnitude*, where competing items are judged based on numerosity. For example, when buying grapes in a grocery store, a shopper might choose one bunch that appears to contain many grapes over another bunch that appears to contain fewer grapes.  On the surface, these two types of judgments seem quite distinct, as they appear to ask different questions -- a physical magnitude judgment asks "how much?", whereas a numerical magnitude judgment asks "how many?"  In spite of this appearance, these two types of judgments can interact in the context of *symbolic* number judgments, where the items to be compared (Arabic number digits) possess both physical magnitude (the physical size of the number digit) and numerical magnitude (the underlying quantity represented by the number digit). The purpose of the present study is to examine the interaction between physical and numerical magnitude in symbolic number judgments.

An example of this interaction occurs in a typical laboratory task where a participant is presented with two number symbols, but one number is presented in a larger font than the other (see Figure \ref{fig:sceFigure}).  Suppose further that the participant is asked to ignore numerical value and choose the *physically* larger digit. Even though numerical magnitude is irrelevant to this comparison task, participants are usually slower to respond on trials where physical and numerical magnitude are incongruent with each other (e.g., a large 2 paired with a small 8, as in the right panel of Figure \ref{fig:sceFigure}), compared to trials on which physical and numerical size are congruent (e.g., a small 2 paired with a large 8, as in the left panel of Figure \ref{fig:sceFigure}). This relative slowdown in the magnitude comparison is called the *size-congruity effect*, a well-studied phenomenon in the fields of decision making and numerical cognition [@pavio1975;@henik1982;@schwarzHeinze1998;@faulkenberryShaki2016].

```{r sceFigure, fig.height=4, fig.width=8, fig.cap="Example stimuli in a physical size comparison task. The left panel depicts a congruent trial, where the physically larger digit (8) is also the numerically larger digit.  The right panel depicts an incongruent trial, where the physically larger digit (2) is the numerically smaller one.", cache=TRUE}

par(mfrow=c(1,2))

plot(x=-10,y=-10, xlim=c(0,1), ylim=c(0,1),
     xaxt="n", yaxt="n", bty="n",
     xlab="", ylab="", main="Congruent", cex.main=1.3)
lines(x=c(0,0), y=c(0,1), lwd=3)
lines(x=c(0,1), y=c(1,1), lwd=3)
lines(x=c(1,1), y=c(1,0), lwd=3)
lines(x=c(1,0), y=c(0,0), lwd=3)
rect(xleft=0, xright=1, ybottom=0, ytop=1, col="gray")
text(x=0.33,y=0.4, "2", cex=2, pos=3)
text(x=0.66,y=0.4, "8", cex=4, pos=3)


plot(x=-10,y=-10, xlim=c(0,1), ylim=c(0,1),
     xaxt="n", yaxt="n", bty="n",
     xlab="", ylab="", main="Incongruent", cex.main=1.3)
lines(x=c(0,0), y=c(0,1), lwd=3)
lines(x=c(0,1), y=c(1,1), lwd=3)
lines(x=c(1,1), y=c(1,0), lwd=3)
lines(x=c(1,0), y=c(0,0), lwd=3)
rect(xleft=0, xright=1, ybottom=0, ytop=1, col="gray")
text(x=0.33,y=0.4, "2", cex=4, pos=3)
text(x=0.66,y=0.4, "8", cex=2, pos=3)
```

One might note that this size-congruity effect is a bit of a curious result; indeed, participants could simply adopt a strategy of ignoring the identity of the numerical digit and simply focus on the physical size, as the task requires. However, the presence of the size-congruity effect implies that individuals simply cannot ignore the numerical value. On its own, the effect is certainly interesting. However, the size-congruity effect may perhaps be even more important for the subsequent debate it has generated concerning the nature of number representation. According to one theoretical account, the size-congruity effect occurs because a digit's physical size and numerical magnitude are both encoded into a common, analog represention, upon which further processing occurs in a serial fashion. This *early interaction* account [@schwarzHeinze1998;@szucs2007;@szucs2008;@reike2017] predicts that the relative slowdown on incongruent trials is due to interference at the *encoding* stage. 

An alternative account posits that physical size and numerical magnitude are encoded separately along independent pathways, and the interference between physical size and numerical magnitude occurs as competition between parallel and partially active response options [@santens2011;@faulkenberryShaki2016]. In contrast to the early interaction account, this *late interaction* account predicts that the locus of the size-congruity effect is not in the encoding stage, but rather in the *decision* stage.

A variety of paradigms have been employed to test between these competing models of the size-congruity effect, including classical response time (RT) tasks [@henik1982], electrophysiological techniques [@schwarzHeinze1998;@szucs2007;@szucs2008], neuroimaging [@cohenKadosh2007], computer mouse tracking [@faulkenberryShaki2016], and visual search [@sobel2016;@sobel2017;@krause2016]. However, the outcomes of these multiple approaches have proved to be equivocal; some studies support the early interaction account, whereas others support the late interaction account. As such, a clear consensus on the origin of the size-congruity effect remains elusive. 

A potentially fruitful method for elucidating the nature of the size-congruity effect may come from employing  *accumulator models* to describe the *distributions* of RTs that are produced in the comparison task. Generally speaking, an accumulator model posits that responses in decision tasks stem from a process that involves noisy accumulation of stimulus information over time. When the accumulated information reaches a certain threshold, a response is initiated.  An advantage of using an accumulator model for modeling RTs is that by fitting such a model, one obtains estimates of distributional parameters that can directly index the underlying cognitive processes involved in the decision, such as the rate of information accumulation, the response threshold, and the duration of non-decision processes including encoding and response production [@anders2016]. Further, these models are quite good at describing the shape of typical RT distributions, which tend to be positively skewed [@luce1986]. From a measurement standpoint, this allows one to model the effects of experimental manipulations on the *entire distribution* of RTs, rather than simply modeling the effects of manipulations on the collapsed means or medians. The use of accumulator models has a rich history in the behavioral sciences [@link1975;@luce1986;@ratcliff2008;@ratcliff2016]. However, the use of such models has been relatively limited in the context of numerical cognition.

Whereas some accumulator models have been quite well studied in the context of two-choice decision tasks, such as the drift diffusion model [@ratcliff2016] and the linear ballistic accumulator model [@brown2008;@heathcote2012], such models are typically best suited for tasks in which the error rate is sufficiently large [@anders2016]. As a consequence, these models are difficult to fit in tasks with very low error rates, such as the ones typically employed in the context of single-digit symbolic number representations. An alternative to the drift diffusion and linear ballistic accumulator models is the *shifted Wald model* [@anders2016;@schwarz2001]. The shifted Wald model is a *single*-boundary accumulator model whose probability density represents the distribution of first-passage times of a continuous diffusion process that drifts (with rate $\gamma$) toward a single boundary of height $\alpha$. Mathematically, the probability density is given by

$$
f(x \mid \gamma,\alpha,\theta) = \frac{\alpha}{\sqrt{2\pi(x-\theta)^3}}\cdot \exp\Biggl(-\frac{(\alpha-\gamma(x-\theta))^2}{2(x-\theta)}\Biggr)
$$
where $x>0$ represents a specific data point (i.e., a single response time), $\gamma$ is the *drift rate*, $\alpha$ is the *response threshold*, and $\theta$ is a rightward shift of the entire distribution that represents *nondecision time*. Descriptively, each parameter characterizes a specific characteristic of the distribution's appearance. This can be seen in Figure \ref{fig:swParameters}, which depicts the effect of selectively increasing each shifted Wald parameter. Increasing drift rate $\gamma$ results in a "spreading out" of the distribution, but leaves the mode relatively stable. Increasing response threshold $\alpha$ increases variance to a lesser extent than does an increase of $\gamma$, but the mode is shifted quite substantially rightward. Increasing nondecision time $\theta$ does not change the variance, but instead results in a pure "shift" of the distribution rightward.

```{r swParameters, message=FALSE,warning=FALSE, fig.height=3, fig.width=8, fig.cap="Effects of manipulating shifted Wald (SW) parameters on the shape of distributions. In all three plots, the solid line depicts a SW density with drift rate = 3, response threshold = 1, and nondecision time = 0.2 sec. The dotted line depicts the resulting density when exactly one of the parameters gets increased.", cache=TRUE}
dwald <- function(x,alpha,gamma){
  return((alpha/(sqrt(2*pi*x^3)))*exp(-(alpha-gamma*x)^2/(2*x)))
}


par(mfrow=c(1,3))
x=seq(0,2,0.001)

plot(x,dwald(x-0.2, alpha=1, gamma=3), type="l", xlab="RT (sec.)",ylab="Density", lwd=2, main=expression(paste("Drift rate ", gamma)), yaxt="none", cex.lab=1.5, cex.main=1.5, cex.axis=1.5)
lines(x, dwald(x-0.2, alpha=1, gamma=1), lwd=2, lty=3)

plot(x,dwald(x-0.2, alpha=1, gamma=3), type="l", xlab="RT (sec.)", ylab="", lwd=2, main=expression(paste("Response threshold ", alpha)),yaxt="none", cex.lab=1.5, cex.main=1.5, cex.axis=1.5)
lines(x, dwald(x-0.2, alpha=2, gamma=3), lwd=2, lty=3)

plot(x,dwald(x-0.2, alpha=1, gamma=3), type="l", xlab="RT (sec.)", ylab="", lwd=2, main=expression(paste("Nondecision time ", theta)),yaxt="none", cex.lab=1.5, cex.main=1.5, cex.axis=1.5)
lines(x, dwald(x-0.5, alpha=1, gamma=3), lwd=2, lty=3)

```


An important consideration for the present study is that each of the three shifted Wald parameters can be interpreted as an index of specific cognitive processes [@schwarz2001;@heathcote2004;@anders2016]. This idea is depicted in detail in Figure \ref{fig:accumulatorFig}.  Specifically, drift rate $\gamma$ indexes rate of information uptake from encoded stimuli, and can be influenced by individual processing differences or stimulus characteristics that reflect task difficulty. Mathematically, the drift rate represents the rate at which information stochastically accumulates toward an absorbing boundary; as such, it is an intuitive proxy for rate of information uptake. Response threshold $\alpha$ represents the height of the absorbing boundary of the accumulator; larger values of $\alpha$ would require the accumulator to proceed longer before "hitting" the boundary. Thus, response threshold $\alpha$ is a natural index of *response caution* in the sense that it represents the amount of accumulated information required before initiating a response. Finally, nondecision time $\theta$ represents a horizontal shift of the accumulator function; this accounts for any elapsed time that is not already accounted for by either drift rate or response threshold.  Thus, nondecision time $\theta$ is used to index any processes that are not related to the decision-related accumulation process, such as low-level perceptual processing or response production (i.e., motor preparation for a button press). 

```{r accumulatorFig, message=FALSE,warning=FALSE, fig.height=6, fig.width=8, fig.cap="The shifted Wald as a cognitive model, describing RT as the time for an accumulator to drift toward and hit a single boundary $\\alpha$ at rate $\\gamma =2.0$. The nondecision time $\\theta =0.15$ represents the component of RT which is not due to this accumulation process. The solid black line represents the accumulator for a single trial, whereas the dashed upper curve represents the shifted Wald distribution formed by collecting RTs for many such trials.", cache=TRUE}

# define a function that outputs a drift diffusion process
gendat = function(ndat = 1000, alpha=0.8, drift=4, dt = 0.01) {
  dat <- array()
  dat[1] <- 0
  for (j in 1:(ndat - 1)) {
    if (dat[j]<alpha){
      dat[j+1] <- min(dat[j] + drift * dt + rnorm(n=1, mean=0, sd=0.01), alpha) 
    }
    else {
      dat[j+1] <- alpha
    }
  }
  invisible(dat)  # same as 'return', but without printing to console    
}

## General settings:
set.seed(15328)
dt <- 0.001
drift <- 2
alpha <- 0.8
theta <- 150
ntime <- 1100
times <- c(1:ntime)

# Plot settings:
numPaths <- 1
ylow <- -0.4
yhigh <- alpha
xhigh <- ntime
greycol <- rgb(red = 100, green = 100, blue = 100, alpha = 170, maxColorValue = 255)
# For transparent lines set, set 'alpha' between 0 (invisible) and 255 (opaque)

# generate random walk
set.seed(15328)
walk = c(rep(0,theta),gendat(ndat = ntime, alpha, drift, dt))[0:ntime]
boundary = min(which(walk>=alpha))

# plot the walk
op <- par(cex.main = 1.5, mar = c(5, 6, 4, 5) + 0.1, mgp = c(3.5, 1, 0), cex.lab = 1.5, 
          font.lab = 2, cex.axis = 1.3, bty = "n", las = 1)
plot(times, walk, 
     type = "l", 
     lwd = 1.2, 
     main = "", 
     ylab = "", 
     xlab = "", 
     axes = FALSE, 
     ylim = c(ylow, yhigh+0.7), 
     xlim = c(0, xhigh), 
     cex.lab = 1, 
     font.lab = 2, 
     cex.axis = 0.9, 
     col = "black", 
     bty = "n")

axis(1, at = c(0, 200, 400, 600, 800, 1000, 1200), 
     lab = c("0", "0.2", "0.4", "0.6", "0.8", 
             "1.0", "1.2"))
axis(2, at = seq(ylow,alpha,0.2), 
     lab = c("-0.4","-0.2","0","0.2","0.4","0.6",expression(paste(alpha," = 0.8"))))
par(las = 0)
mtext("Time (sec.)", side = 1, line = 2.5, cex = 1.5, at=ntime/2)
#mtext("Evidence", side = 2, line = 2.8, cex = 1.5, at=10)
lines(c(1, ntime), c(alpha, alpha), lwd = 1, lty = 2, col = "black")

# build "RT" segment
lines(x=c(0,boundary), y=c(-0.3,-0.3), lwd=1.5)
lines(x=c(0,0), y=c(-0.27,-0.33), lwd=1.5)
lines(x=c(boundary,boundary), y=c(-0.27,-0.33), lwd=2)
text(x=boundary/2, y=-0.36, "RT")

# build drift segment
arrows(x0=200, y0=0.2, x1=350, y1=0.2+drift*150/1000, length=0.1, lwd=1.5)
text(200,0.35, expression(paste(gamma," = 2.0")))

# build theta segment
lines(x=c(0,theta), y=c(-0.2,-0.2), lwd=1.5)
lines(x=c(0,0), y=c(-0.17,-0.23), lwd=1.5)
lines(x=c(theta,theta), y=c(-0.17,-0.23), lwd=1.5)
text(theta/2, -0.12, expression(paste(theta," = 0.15")))

# plot shifted wald model
SW <- function(x,gamma,alpha,theta){
  y <- alpha/sqrt(2*pi*(x-theta)^3)*exp(-1*(alpha-gamma*(x-theta))^2/(2*(x-theta)))
  return(y)
}

ystart <- yhigh
c = 0.3 # adjust scale factor to make density plot fit onto previous plot
x<-1:ntime
y<-SW(x/1000,alpha=alpha,gamma=drift,theta=0.15)
lines(x,y*c+ystart,lwd=1.5,col="black",lty=2)
```

Several recent studies have used the shifted Wald distribution to index processes in cognitive tasks. For example, @anders2015 fit RT distributions in a picture naming task and found that greater semantic interference resulted in slower drift rate (i.e., slower information accumulation) and larger response threshold, but no change in nondecision time. These effects on the shifted Wald parameters were largely consistent with predictions of the "dark-side model", a model of lexical choice in psycholinguistics [@oppenheim2010]. Another example in the context of numerical cognition comes from @faulkenberry2017, who had participants complete an addition verification task under varying problem formats (words or digits). He found that presenting problems in word format resulted in a decrease in drift rate, concluding that the effect of problem format is not isolated to the encoding stage, but rather has a direct impact on calculation processes as well. This result was interpreted as support for an interactive model of mental arithmetic processing [@campbell1988;@campbell2004]. 

Against this background, the aim of the present study is to use the shifted Wald distribution as a model to permit a fine-grained examination of the size-congruity effect. Instead of collapsing participants' RT distributions to single-valued summary statistics (e.g., means or medians) and examining the effect of physical-numerical size congruity on these means/medians, we instead fit the distributions to a shifted Wald distribution, which yields estimates of drift rate, response threshold, and nondecision time in each experimental condition.  If the early interaction account is correct, one should expect the size congruity effects to stem from the stimulus encoding stage, and thus, one should see a congruity effect on our estimates of nondecision time.  If, on the other hand, the late interaction account is correct, the size congruity effect should stem from post-encoding decision processes, and thus, one should see congruity effects on our estimates of drift rate and response threshold.

# Method

## Participants
Twenty-three undergraduate psychology students participated in the experiment for partial course credit. Informed consent was obtained from all individuals who participated in the study.

## Stimuli and procedure

The experiment was implemented via the OpenSesame software package [@opensesame], which was run on a 20 inch iMac computer with a screen resolution of 1680 x 1050 pixels.  Participants used a standard Dell keyboard for input. At the beginning of the experiment, participants were told that they would be presented with pairs of numbers, with each number being displayed in a different font size.  Furthermore, they were told to quickly and accurately indicate (via a keypress) which digit was physically larger, pressing the "A" key if the number on the left was larger, and pressing the "L" key if the number on the right was larger.

The number pairs were constructed from the single-digit Arabic numerals 2, 3, 4, 5, 6, 7, and 8.  Pairs were chosen in order to balance the numerical distance between numerals. Ignoring order, there were 12 possible pairs of numbers: 2-3, 3-4, 4-5 (distance 1); 2-4, 3-5, 4-6 (distance 2); 2-5, 3-6, 4-7 (distance 3); 2-6, 3-7, 4-8 (distance 4).  

The size-congruity manipulation was created by varying the font size of each digit in the number pair. Specifically, the physically smaller digit was presented in 28 point font, whereas the physically larger of the pair was presented in 36 point font. This resulted in two different congruity conditions -- *congruent* trials, in which the numerically larger digit was also physically larger, and  *incongruent* trials, in which the numerically larger digit was physically smaller. Each pair was also presented in two different left-right orders and two different font configurations (smaller/left;larger/right or smaller/right;larger/left). In all, this resulted in $12 \times 2 \times 2 \times 2 = 96$ experimental trials per block.  

Participants completed 4 blocks of these 96 experimental trials (384 trials total) in a single experimental session lasting approximately 20 minutes. Each experimental trial began with a fixation cross displayed for 500 milliseconds, followed immediately by a pair of numbers. The center of the leftmost number was positioned 300 pixels (12.5 degrees) to the left of the center of the screen, whereas the center of the rightmost number was positioned 300 pixels (12.5 degrees) to the right of center (resulting in a visual angle between numbers of approximately 25 degrees). For each trial, the number pair remained on the screen until a response was made. If the response was correct, no feedback was given, and the next trial began immediately. If the response was incorrect, a red "X" was presented in the center of the screen for 1 second, after which the next trial began.

All data from this experiment were uploaded nightly to Github via a *born open* protocol [@rouder2016]. These data (along with the experiment script) are available for download at https://git.io/vAEE8.

# Results

```{r datagrab, cache=TRUE}
##############
#DATA SETUP
##############

# import data
dataRaw <- read_csv("https://raw.githubusercontent.com/tomfaulkenberry/physNumComparisonTask/master/results/processed.csv")

# basic info
nSub = length(unique(dataRaw$subject_nr))
nTrials = dim(dataRaw)[1]
numErrors = sum(dataRaw$correct==0)
medianRT = median(dataRaw$response_time)
MAD = mad(dataRaw$response_time)
numOutliers = sum(dataRaw$correct==0 | dataRaw$response_time < medianRT-3*MAD | dataRaw$response_time > medianRT+6*MAD) - numErrors
numRetained = nTrials-numErrors-numOutliers
  
data = dataRaw %>%
   filter(correct==1 & response_time>medianRT-3*MAD & response_time<medianRT+6*MAD) %>%
   mutate(rt = response_time/1000)

```

Participants completed a total of `r nTrials` experimental trials.  We discarded `r numErrors` trials that contained an incorrect response (error rate = `r round(100*numErrors/nTrials,2)`%).  Further, we removed an additional `r numOutliers` trials for which response time was below three median absolute deviations (MAD) and above six MAD from the overall median RT (median RT = `r medianRT` msec, MAD = `r round(MAD,2)` msec) [@leys2013].  This cleaning procedure resulted in retaining a total of `r numRetained` trials (`r round(100*numRetained/nTrials,1)`% of original trials) for further analysis.

The general analysis plan throughout the paper is as follows.  First, each hypothesis test was computed as a traditional frequentist test (specifically, a paired-samples $t$-test). Afterward, we performed a default Bayesian $t$-test [@rouder2009] to obtain a *Bayes factor*, a likelihood ratio which provides a continuous measure of the extent to which the observed data is more likely to have occurred under one hypothesis than another [@kass1995]. As such, the Bayes factor provides a direct index of our relative belief in one of two competing hypotheses. Notationally, $B_{10}$ represents a Bayes factor for the alternative over the null, whereas $B_{01}$ represents a Bayes factor for the null over the alternative. This approach is especially useful in the case of null effects, which cannot be coherently argued for within a frequentist framework [@wagenmakers2007]. As recommended by [@dienes2018], we combine both frequentist and Bayesian procedures in our reporting. By doing this, we can combine the familiarity of the orthodox frequentist approach with a Bayesian measure of evidential value that is provided by our data.  

```{r densities, fig.width= 6,fig.height=4,fig.cap="Distributions of response times (in seconds) as a function of congruity (congruent versus incongruent).",cache=TRUE}

data %>%
  ggplot(aes(x=rt, group=congruity)) +
  geom_density(aes(fill=congruity, linetype=congruity), alpha=0.5) +
  theme_classic(14) +
  scale_fill_grey(start=0.2,end=0.8) +
  xlab("RT (sec)") +
  theme(legend.title=element_blank())
```

```{r tTests, cache=TRUE}
detach(package:plyr)
agg = data %>%
  group_by(subject_nr,congruity) %>%
  summarize(medRT = median(rt), meanRT=mean(rt), sdRT = sd(rt))

diff = mean(agg$medRT[agg$congruity=="incongruent"])-mean(agg$medRT[agg$congruity=="congruent"])

medianT = apa_print(t.test(agg$medRT[agg$congruity=="incongruent"], agg$medRT[agg$congruity=="congruent"], paired=TRUE, alternative="greater"))

medianBayes = ttestBF(agg$medRT[agg$congruity=="incongruent"], agg$medRT[agg$congruity=="congruent"], paired=TRUE, nullInterval=c(0,Inf))

sdT = apa_print(t.test(agg$sdRT[agg$congruity=="incongruent"], agg$sdRT[agg$congruity=="congruent"], paired=TRUE, alternative="greater"))

sdBayes = ttestBF(agg$sdRT[agg$congruity=="incongruent"], agg$sdRT[agg$congruity=="congruent"], paired=TRUE, nullInterval = c(0,Inf))

```

As expected, we found a significant size congruity effect on RTs in the physical comparison task. As can be seen in Figure \ref{fig:densities}, the peak of the RT distribution for incongruent trials was shifted rightward compared to the distribution for congruent trials, indicating that incongruent trials took longer to compare than congruent trials.  This was confirmed by a paired samples $t$-test, from which we found a signficant effect of congruity on median RTs, `r medianT$statistic`. On average, responses for incongruent trials were `r round(1000*diff,0)` milliseconds slower than congruent trials. This result was well supported by a Bayesian $t$-test, which produced a Bayes factor of $B_{10}=$ `r exp(medianBayes@bayesFactor$bf[1])`. This indicates that the observed data are approximately `r round(exp(medianBayes@bayesFactor$bf[1]),0)` times more likely under the alternative hypothesis than the null hypothesis, which provides substantial evidence in favor of a congruity-related increase in median RT.

Also apparent from Figure \ref{fig:densities} is an increase in the spread of the RT  distribution for incongruent trials.  This was again confirmed by a paired samples $t$-test: standard deviations were signficantly larger for incongruent trials compared to congruent trials, `r sdT$statistic`. Similar to median RTs, a Bayesian $t$-test produced a Bayes factor of $B_{10}=$ `r exp(sdBayes@bayesFactor$bf[1])`.  As with median RTs, this result implies that the observed data are approximately `r round(exp(sdBayes@bayesFactor$bf[1]),0)` times more likely under the alternative than the null, giving us much evidence in favor of a congruity-related increase in standard deviations.


```{r waldModel, fig.width=8, fig.height=3, fig.cap="Means of shifted Wald parameters presented as a function of congruity (congruent versus incongruent). Panel A depicts drift rate, which indexes rate of information accumulation from stimuli. Panel B depicts response threshold, which indexes the amount of accumulated information required before response initiation. Panel C depicts nondecision time, which indexes the amount of time required for nondecision processes (e.g., encoding and response generation).", cache=TRUE}

fit = swapply(dat=data, obsvar="rt", facs = c("congruity", "subject_nr")) 

params = fit$vars
params$subject_nr = as.factor(params$subject_nr)
params$congruity = factor(params$congruity, labels=c("congruent","incongruent"))

detach(package:plyr)
gammaPlot = params %>%
  group_by(congruity) %>%
  summarize(mean = mean(gamma), se = sd(gamma)/sqrt(23)) %>%
  ggplot(aes(x=congruity, y=mean)) +
  geom_bar(stat="identity", fill="gray", colour="black", width=0.5) +
  geom_errorbar(width=0.1,aes(ymin=mean-se,ymax=mean+se)) +
  theme_classic(14) +
  ylab(expression(paste("Drift rate ",gamma)))
  
alphaPlot = params %>%
  group_by(congruity) %>%
  summarize(mean = mean(alpha), se = sd(alpha)/sqrt(23)) %>%
  ggplot(aes(x=congruity, y=mean)) +
  geom_bar(stat="identity", fill="gray", colour="black", width=0.5) +
  geom_errorbar(width=0.1,aes(ymin=mean-se,ymax=mean+se)) +
  theme_classic(14) +
  ylab(expression(paste("Response threshold ",alpha)))
  
thetaPlot = params %>%
  group_by(congruity) %>%
  summarize(mean = mean(theta), se = sd(theta)/sqrt(23)) %>%
  ggplot(aes(x=congruity, y=mean)) +
  geom_bar(stat="identity", fill="gray", colour="black", width=0.5) +
  geom_errorbar(width=0.1,aes(ymin=mean-se,ymax=mean+se)) +
  theme_classic(14) +
  ylab(expression(paste("Nondecision time ",theta)))
  
plot_grid(gammaPlot,alphaPlot,thetaPlot, nrow=1, ncol=3, labels="AUTO")

gammaCong = params$gamma[params$congruity=="congruent"]
gammaIncong = params$gamma[params$congruity=="incongruent"]
gammaT = apa_print(t.test(gammaIncong,gammaCong, paired=TRUE, alternative=c("less")))
gammaBF = ttestBF(gammaIncong,gammaCong, paired=TRUE, nullInterval=c(-Inf,0))

alphaCong = params$alpha[params$congruity=="congruent"]
alphaIncong = params$alpha[params$congruity=="incongruent"]
alphaT = apa_print(t.test(alphaIncong,alphaCong, paired=TRUE, alternative="greater"))
alphaBF = ttestBF(alphaIncong,alphaCong, paired=TRUE, nullInterval = c(0,Inf))

thetaCong = params$theta[params$congruity=="congruent"]
thetaIncong = params$theta[params$congruity=="incongruent"]
thetaT = apa_print(t.test(thetaIncong,thetaCong, paired=TRUE, alternative="greater"))
thetaBF = ttestBF(thetaIncong,thetaCong, paired=TRUE, nullInterval = c(0,Inf))
```

```{r resultsTable, results="asis",  include=TRUE}
detach(package:plyr)

aggParams = params %>%
  group_by(congruity) %>%
  summarize(meanGamma=mean(gamma), sdGamma=sd(gamma),
            meanAlpha=mean(alpha), sdAlpha=sd(alpha),
            meanTheta=mean(theta), sdTheta=sd(theta)
            )

apa_table(
  aggParams,
  caption = "Descriptive statistics for shifted Wald parameters",
  col.names = c("Congruity","$M$", "$SD$", "$M$","$SD$","$M$","$SD$"),
  #note = "Mean RT and SD were computed for correct trials only.",
  col_spanners = list("Drift rate $\\gamma$" = c(2,3),
                      "Response threshold $\\alpha$" = c(4,5),
                      "Nondecision time $\\theta$"=c(6,7)),
  align = c("l", "c", "c", "c","c","c","c"),
  note = "M = mean, SD = standard deviation",
  escape=TRUE,
  landscape=FALSE)


```

Next, we attempted to more fully describe the effects of physical-numerical size congruity on the *distributions* of response times. To this end, we fit the distributions with a shifted Wald model. Specifically, each participant's distribution of RTs was split into congruent trials and incongruent trials.  Then, each of these two distributions was fit with a shifted Wald model using the method of @anders2016. This resulted in a collection of parameters $\gamma$ (drift rate), $\alpha$ (response threshold), and $\theta$ (nondecision time) for each of the `r nSub*2` combinations of congruity (congruent, incongruent) and participant ($N=$ `r nSub`).  We then tested the effects of congruity on the shifted Wald parameters by submitting each parameter to a paired samples $t$-test. As above, we further validated each result by measuring the evidential value of data in each test via a Bayesian $t$-test.

The effects of physical-numerical size congruity on each shifted Wald parameter can be seen in Table \ref{tab:resultsTable} as well as in Figure \ref{fig:waldModel}. For drift rate $\gamma$, there was a significant effect of congruity, `r gammaT$statistic`. As can be seen in Figure \ref{fig:waldModel}A, mean drift rate was smaller for incongruent trials ($M=$ `r mean(gammaIncong)`) than for congruent trials ($M=$ `r mean(gammaCong)`). This indicates that the rate of information accumulation from incongruent trials was reduced compared to trials in which the physical magnitude comparison was congruent with the numerical magnitude comparison. A Bayesian $t$-test yielded a Bayes factor of $B_{10}=$ `r exp(gammaBF@bayesFactor$bf[1])`. This indicates that the observed data are approximately `r round(exp(gammaBF@bayesFactor$bf[1]),0)` times more likely under the alternative hypothesis than the null hypothesis, which provides very strong evidence in favor of a congruity-related decrease in drift rate.

Figure \ref{fig:waldModel}B shows that congruity also had a significant effect on response threshold $\alpha$, albeit in the opposite direction, `r alphaT$statistic`. The mean response threshold was larger for incongruent trials ($M=$ `r mean(alphaIncong)`) than for congruent trials ($M=$ `r mean(alphaCong)`), which indicates that in addition to a reduction in the *rate* of information accumulation on incongruent trials compared to congruent trials, participants also required more information before making a decision on such trials. A Bayesian $t$-test resulted in a Bayes factor of $B_{10}=$ `r exp(alphaBF@bayesFactor$bf[1])`, indicating that the observed data are approximately `r round(exp(alphaBF@bayesFactor$bf[1]),0)` times more likely under the alternative hypothesis than the null. Such a Bayes factor is generally interpreted as positive evidence in favor of a congruity-related increase in response threshold.

Finally, Figure \ref{fig:waldModel}C shows that congruity did not have a significant effect on nondecision time $\theta$, `r thetaT$statistic`.  Note that in a frequentist framework, the absence of a significant effect does not constitute evidence for a null effect [@wagenmakers2007]. We can, however, measure the evidence for a null effect using a Bayes factor. To this end, a Bayesian $t$-test produced a Bayes factor of $B_{01}=$ `r 1/exp(thetaBF@bayesFactor$bf[1])`, which means that the observed data were approximately `r round(1/exp(thetaBF@bayesFactor$bf[1]),0)` times more likely under the null hypothesis than the alternative hypothesis, giving us positive evidence in favor of a null effect of congruity on nondecision time.

# Discussion

The purpose of the present study was to use response time modeling to provide a fine-grained examination of the timecourse of the size congruity effect. Specifically, we aimed to use the results of this modeling to test between two competing models of the size congruity effect: an *early interaction* model, where the interference between physical and numerical magnitude is purported to be an *encoding* effect which occurs an at early representational stage, and a *late interaction* model, where interference occurs at later, *decision*-related stages.

As was expected, we found a large effect of physical-numerical congruity on median response times, which incongruent trials requiring significantly more time for comparison than congruent trials. Further, we found that the standard deviation of the response time distributions increased for incongruent trials. Such an increase in both the center and spread of the response time distributions indicates a need for more fine-grained analysis of the effects of congruity on the response times distributions. To this end, we used a shifted Wald distribution [@anders2016], a single-boundary accumulator model, to provide a three-parameter description of the distributions in each congruity condition.

We found that congruent trials resulted in signficant changes to two of the three shifted Wald parameters. The observed increase in median RT and standard deviation that occured for incongruent trials was due primarily to a decrease in drift rate and an increase in response threshold. The decrease in drift rate means that, for incongruent trials, stimulus information was accumulated more slowly than for congruent trials. Simultaneously, there was an increase in response threshold, indicating that participants adopted a larger threshold for information that was required to be accumulated before making a decision.  Critically, there was no effect of congruity on nondecision time. In all, the present data indicates that the congruity manipulation had effects on decision-related parameters (drift rate and response threshold) and no direct effect on the parameter related to encoding (nondecision time). By implication, the mismatch between numerical and physical size seems to impede participants' ability to extract magnitude information from the encoded stimuli as well as increase participants' threshold for information required before initiating a response.  However, there seems to be no effect of congruity on early perceptual processing. As such, the pattern of observed behavior lends direct support to a *late interaction* model of the size congruity effect.

Such a conclusion is in general agreement with several other recent studies on the locus of interference in the size congruity effect, which have used a variety techniques ranging from visual search [@sobel2016;@sobel2017] to computer mousetracking [@faulkenberryShaki2016]. The cumulative data from these studies lend converging evidence on the late-interaction account of the size congruity effect. In turn, these data further support to a response competition model of number comparison put forth by Verguts and colleagues [@gevers2006;@verguts2005].  

The present study is also novel in its use of response time modeling in the context of numerical cognition. Such models have been used successfully in a variety of other domains, and their advantages have been discussed previously. Note that we chose to a version of the number comparison task where participants were asked to choose the physically larger of the two presented digits. One could have easily used a version where participants are asked to choose the *numerically* larger of the two digits. Indeed, this would be an interesting direction for future work, as @arend2015 recently showed that the size-congruity effect is larger for the numerical version of the task. In this task, one must additionally consider the instruction ("choose larger" versus "choose smaller"), as Arend and Henik also demonstrated that the "choose larger" instruction resulted in the larger size-congruity effect. This modulation of task instruction [see also @faulkenberry2018] could very well have important downstream consequences for our modeling work here, and as such, a full interpretation of our results is necessarily tentative until further study can be completed. 

In summary, the present data shows that the size congruity effect in physical number comparison arises due to late, response-related decision processes, and is not localized to an early encoding stage.  As such, the data lends support for a late-interaction account of the size congruity effect.




#### Conflict of interest
On behalf of all authors, the corresponding author states that there is no conflict of interest. 

#### Ethical approval
All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.

#### Informed consent
Informed consent was obtained from all individual participants included in the study.

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
